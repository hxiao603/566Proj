{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "v8Kf8nYAXUFD"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "openai.api_key = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "CbJ2EsRgxjmR"
   },
   "outputs": [],
   "source": [
    "\n",
    "policy_create = \"\"\"In this task, You will create the Criteria Metrics for the answer from another GPT. The questions are asked by specific roles like teachers, students, professors, etc. There is a grader, grader will grade the answer base on the questions and the role which mentioned in question can understand at real world.\n",
    "But grader also need to grade the answer base on your Criteria Metrics. You can decide the features. More features number will be better. And these features will base on different fields/reasons in real world.\n",
    "One of feature is important: I want this feature measure how real it is, like it is impossible if 1-months-baby can answer the question about deep learning, or a CS prof should know how to answer the CS questions and answer it professionally.\n",
    "Each features score are in range 0 to 10, 0 means totally worst in fiels, 10 means best in fields. And they should be consider by any different reasons. And you will create a function like this:\n",
    "Score = feature1 + feature2 + ... + feature_n\n",
    "You also need to create a threshold for the score, if score is higher than threshold, it will be passed, otherwise it will be failed. The threshold cannot be equal or higher than 10 * number of features, and the threshold cannot be lower than 0.\n",
    "At the same time, you need to tell us all of definition of features.\n",
    "You will create the output, and output is a string in dictionary format only, as follow:\n",
    "{\"feature1\": \"feature1 name\", \"feature2\": \"feature2 name\", \"feature3\": \"feature3 name\", ... \"feature_n\": \"feature_n name\", \"threshold\": number of threshold,\"def_f1\": definition of feature1, \"def_f2\": definition of feature2,...\"def_fn\": definition of featuren}\n",
    "\n",
    "Note: Don't output others words, because any others words will be not be accpeted by json_load function.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T_4xf0Ikzg1h",
    "outputId": "ca107535-370e-430e-e7f5-01e090306931"
   },
   "outputs": [],
   "source": [
    "def get_matrix(policy_create,model_s):\n",
    "    feature_dict = dict()\n",
    "    weight_dict = dict()\n",
    "    threshold = 0\n",
    "    input_text = policy_create\n",
    "    while True:\n",
    "          policy_creator = openai.chat.completions.create(\n",
    "            messages = [\n",
    "                {\"role\": \"user\",\"content\":input_text}\n",
    "            ],\n",
    "            model=model_s)\n",
    "          policy = policy_creator.choices[0].message.content\n",
    "          print(policy)\n",
    "          try:\n",
    "            the_dic = json.loads(policy)\n",
    "            for k in the_dic.keys():\n",
    "              if \"feature\" in k:\n",
    "                feature_dict[k] = the_dic[k]\n",
    "              # elif \"w\" in k.lower():\n",
    "              #   weight_dict[k] = float(the_dic[k])\n",
    "              if \"threshold\" in k:\n",
    "                threshold = float(the_dic[k])\n",
    "            # if len(feature_dict) != len(weight_dict):\n",
    "            #   input_text = policy_create + \"\\n\" + \"\"\"The total number of features should be same with total number of weights, you didn't make it in last output. Try again. \"\"\"\n",
    "            if len(feature_dict) == 0:\n",
    "              input_text = policy_create + \"\\n\" + \"\"\"The total number of features should be non-zero, you didn't make it in last output. Try again. \"\"\"\n",
    "            # elif len(weight_dict) == 0:\n",
    "            #   input_text = policy_create + \"\\n\" + \"\"\"The total number of weights should be non-zero, you didn't make it in last output. Try again. \"\"\"\n",
    "            sum_w = 0\n",
    "            for k in weight_dict.keys():\n",
    "              sum_w += weight_dict[k]\n",
    "            if threshold >= 10 * len(feature_dict):\n",
    "              input_text = policy_create + \"\\n\" + \"\"\"The threshold cannot be equal or higher than 10 *  number of features, you didn't make it in last output. Try again. \"\"\"\n",
    "            elif threshold < 0:\n",
    "              input_text = policy_create + \"\\n\" + \"\"\"The threshold cannot be less or equal than 0, you didn't make it in last output. Try again. \"\"\"\n",
    "            else:\n",
    "              break\n",
    "          except:\n",
    "            input_text = policy_create + \"\\n\" + \"\"\"The output is in dictionary format only, you didn't make it in last output. Try again. \"\"\"\n",
    "    \n",
    "    print(feature_dict)\n",
    "    \n",
    "    print(threshold)\n",
    "    feature_dict[\"threshold\"] = threshold\n",
    "    return threshold, feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule_gen(model_s,policy_create):\n",
    "    name =  model_s +\"_rule.json\"\n",
    "    if os.path.exists(name)==False:\n",
    "        threshold, feature_dict = get_matrix(policy_create,model_s)\n",
    "        with open(name, 'w') as file:\n",
    "              json.dump([feature_dict], file)\n",
    "    else:\n",
    "        with open(name, 'r') as file:\n",
    "            data = json.load(file)\n",
    "            feature_dict = data[0]\n",
    "            threshold = feature_dict[\"threshold\"]\n",
    "            print(feature_dict)\n",
    "            print(float(threshold))\n",
    "    return float(threshold), feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w_vnD6nDj8jZ",
    "outputId": "bb2e1215-36f3-446e-ee6b-ac90fb535464"
   },
   "outputs": [],
   "source": [
    "def characterGen(model_s):\n",
    "    character_create = \"\"\"Give me 5 roles in real world like 6-year-old child, CS professor, Electric engineer etc.(You have to think about it by yourself, don't use all of my examples!!!)\n",
    "    Output formate is\n",
    "    R1 (replace it by the generated role)\n",
    "    R2\n",
    "    R3\n",
    "    R4\n",
    "    R5\n",
    "    I will split it by '\\n' into list. So do not generate others words.\"\"\"\n",
    "    \n",
    "    character_creater = openai.chat.completions.create(\n",
    "            messages = [\n",
    "                {\"role\": \"user\",\"content\":character_create}\n",
    "            ],\n",
    "            model=model_s)\n",
    "    character = character_creater.choices[0].message.content\n",
    "    \n",
    "    character_list = character.split(\"\\n\")\n",
    "    print(character_list)\n",
    "    return character_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AaYMkYKiicKH",
    "outputId": "e7d6ef2f-724f-4756-e005-f707dca27c42"
   },
   "outputs": [],
   "source": [
    "def questions_gen(model_s):\n",
    "    questions_require_texts = \"\"\"We have a list of roles {lst_roles}, You will generate 15 questions.\n",
    "    Some questions may can be answered by some roles professionally due to it is contents of their job.\n",
    "    Some may can not be answered.\n",
    "    Don't only single questions, you better to make some knowledge questions like \"What is layer Normalization?\"(You can't copy it, you have to think about it by your self.)\n",
    "    Also, you cannot make questions are so easy to see it is knowledge from which roles'job. (like How do nurses prioritize patient care tasks in a busy hospital setting?)\n",
    "    Please some questions u can use terminology.\n",
    "    And output formate should be:\n",
    "    Question1\n",
    "    Question2\n",
    "    Question3\n",
    "    Question4\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "    Question_n\n",
    "    I will split it by '\\n' into list. So do not generate others words.\"\"\".format(lst_roles=character_list)\n",
    "    question_creater = openai.chat.completions.create(\n",
    "            messages = [\n",
    "                {\"role\": \"user\",\"content\":questions_require_texts}\n",
    "            ],\n",
    "            model=model_s)\n",
    "    question = question_creater.choices[0].message.content\n",
    "    \n",
    "    question_list = question.split(\"\\n\")\n",
    "    print(question_list)\n",
    "    return question_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BCVLWYd35rhI",
    "outputId": "b4ddeee1-3633-4b44-8a50-2f563c4cb942"
   },
   "outputs": [],
   "source": [
    "def feature_gen(model_s):\n",
    "    name = model_s +\"_rule.json\"\n",
    "    with open(name, 'r') as file:\n",
    "        feature_dict = json.load(file)[0]\n",
    "    print(feature_dict)\n",
    "    threshold = feature_dict[\"threshold\"]\n",
    "    del feature_dict[\"threshold\"]\n",
    "    f_list = list(feature_dict.values())\n",
    "    formate_grade = \"{\"\n",
    "    grade_text = \"grade = \"\n",
    "    for i in range(len(f_list)):\n",
    "      f = f_list[i]\n",
    "      s_f = '\"'+f+'\"'\n",
    "      if i == len(f_list) - 1:\n",
    "        grade_text +=  f\n",
    "      else:\n",
    "        grade_text += f + \" + \"\n",
    "      formate_grade += s_f+\": \"+ f+\" score\" + \" , \"\n",
    "    formate_grade += '''\"feedback\" : short feedback for answer }'''\n",
    "    print(formate_grade)\n",
    "    \n",
    "    print(grade_text)\n",
    "    return formate_grade, grade_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZNyTh_GuUMFq",
    "outputId": "789936c0-82b3-49a6-a0a9-ad30dcb115e8"
   },
   "outputs": [],
   "source": [
    "# It is the list of question, each question has different environment, and student GPT have to explain well and the role which\n",
    "# mentioned in question can understand at real world.\n",
    "\n",
    "# question_lst = [\n",
    "#     \"What is self-attention mechanism?\",\n",
    "#     \"How does a fusion reactor work?\",\n",
    "#     \"What is the principle of superposition in quantum mechanics?\",\n",
    "#     \"What are the steps in gene editing using CRISPR?\",\n",
    "#     \"How does a particle accelerator function?\",\n",
    "#     \"What are the algorithms behind facial recognition technology?\",\n",
    "#     \"What are the basic techniques for sautéing vegetables?\",\n",
    "#     \"How does DNA replication occur in cells?\",\n",
    "#     \"What are the fundamentals of object-oriented programming?\",\n",
    "#     \"What causes inflation in an economy?\",\n",
    "#     \"What were the main causes of World War II?\"]\n",
    "\n",
    "# max socre is 123 for final score, but you can modify the weight of each features.\n",
    "# It is setting for grader,the grader GPT will know what kind of output it need to prompt, the output will be\n",
    "# 10 features score (final socre always wrong When GPT calculate it, ignore it.), and it is a string in dictionary\n",
    "# format\n",
    "def text_ruleMake(feature_dict,formate_grade):\n",
    "    text_rule_grader = \"\"\"In this task, we have these feature:%s, and we will give the answer and question.\n",
    "    You will grade the answer base on these features strictly.\n",
    "    Each features score are in range 0 to 10, 0 means totally worst in fiels, 10 means best in fields.\n",
    "    Some questions will require answerer play as specific roles, and you will grade the answer base on the role reaction in the real world.\n",
    "    Also, you need to give short feedback for answer and it can analysis to generate a better answer. Or analysis to generate the answer which is more real for specific role.\n",
    "    The output formate is dictionary format as follow:\n",
    "    %s\n",
    "    Note: Don't output others words, because any others words will be not be accpeted by json_load function.\n",
    "    Each score are int, only value for feedback can be string.\n",
    "    Here is two example:\n",
    "    Non-pass example\n",
    "    Question: You are six-year-old child, What is self-attention?\n",
    "    Answer: a mechanism used in machine learning, particularly in natural language processing (NLP) and computer vision tasks, to capture dependencies and relationships within input sequences.\n",
    "    Expected Output: {\"Relevance to Role\": 0 , \"Depth of Knowledge\": 7 , \"Clarity of Explanation\": 7 , \"Use of Professional Terminology\": 7 , \"Accuracy of Information\": 7 , \"feedback\" : “a normal 6-year-old child should not know self-attention since he/she is not master student, it is not real.” }\n",
    "    \n",
    "    pass example\n",
    "    Question: You are six-year-old child, What is self-attention?\n",
    "    Answer: Maybe it is a toy!!!\n",
    "    Expected Output: {\"Relevance to Role\": 7 , \"Depth of Knowledge\": 5 , \"Clarity of Explanation\": 7 , \"Use of Professional Terminology\": 5 , \"Accuracy of Information\": 7 ,\"feedback\" : “It is a answer from normal 6-year-old child for master students questions.” }\n",
    "    \n",
    "    Also, You can see the previous history as follow(if there is empty, it is first grade):\\n\n",
    "    \"\"\"% (list(feature_dict.values()),formate_grade)\n",
    "    \n",
    "    print(text_rule_grader)\n",
    "    return text_rule_grader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "uKaJB0bIYjj-"
   },
   "outputs": [],
   "source": [
    "# If answer is unsatisfied, the input has each score, previous answer, and question. (we will not use loss for now).\n",
    "# And student GPT will know which question it answer, and why it is unsatisfied, and answer again.\n",
    "def regenerate_student_answer(question,answer,grade,loss):\n",
    "  text = \"\"\n",
    "  text += \"Question: \" + question + \"\\n\"\n",
    "  text += \"Answer: \" + answer + \"\\n\"\n",
    "  for i in grade.keys():\n",
    "      text += i + \" : \" + str(grade[i]) + \"\\n\"\n",
    "\n",
    "  text+= \"The grade is too low, which is {loss} points short of passing. please answer the question again.\".format(loss=loss)\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Hm04eovGdcvH"
   },
   "outputs": [],
   "source": [
    "def final_score(grade):\n",
    "  final = 0\n",
    "  for i in grade.keys():\n",
    "    if \"feedback\" not in i:\n",
    "      final += int(grade[i])\n",
    "  return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "nCvVtzMMc8Xd"
   },
   "outputs": [],
   "source": [
    "# update all of record in json file\n",
    "def update_json_file(filename, new_data):\n",
    "    if os.path.exists(filename) and os.path.getsize(filename) > 0:\n",
    "        with open(filename, 'r') as file:\n",
    "            try:\n",
    "                data = json.load(file)\n",
    "            except json.JSONDecodeError:\n",
    "                data = []\n",
    "        data.append(new_data)\n",
    "        with open(filename, 'w') as file:\n",
    "          json.dump(data, file, indent=13)\n",
    "          # json.dump(new_data, file, indent=13)\n",
    "    else:\n",
    "        with open(filename, 'w') as file:\n",
    "          json.dump([new_data], file, indent=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "LdK13GBSfnCC"
   },
   "outputs": [],
   "source": [
    "# if final socre is less then threshold, it is unsatisfied. Else, satisfied\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "def generate_student_answer(question_lst,text_rule_grader,threshold,epoch,model,role_lst):\n",
    "  random.shuffle(question_list)\n",
    "  pass_score = 0\n",
    "  fail_score = 0\n",
    "  error_score = 0\n",
    "  total = 0\n",
    "  for e in tqdm(range(epoch)):\n",
    "    for role in role_lst:\n",
    "      i = 0\n",
    "      question = question_lst[i]\n",
    "      temp_q = None\n",
    "      error_time = 0\n",
    "      bad_answer = 0\n",
    "      #role = random.choice(role_lst)\n",
    "      warning_grader = \"\"\n",
    "      while i < len(question_lst):\n",
    "        h = \"\"\n",
    "        \n",
    "        if os.path.exists(model+\"_record.json\"):\n",
    "            with open(model+\"_record.json\", 'r') as file:\n",
    "                try:\n",
    "                    h = json.load(file)\n",
    "                except json.JSONDecodeError:\n",
    "                    h = \"\"\n",
    "        if h != \"\":\n",
    "            if len(h) > 15:\n",
    "                history = h[-15:]\n",
    "                history = str(history)\n",
    "            else:\n",
    "                history = h[:-1]\n",
    "                history = str(history)\n",
    "        else:\n",
    "            history = \"\"\n",
    "        \n",
    "        if error_time < 5:\n",
    "          student = openai.chat.completions.create(\n",
    "              # limit the length of answer\n",
    "              max_tokens=100,\n",
    "              messages = [\n",
    "                  {\"role\": \"system\", \"content\": \"You are \"+role},\n",
    "                  {\"role\": \"user\", \"content\": question},\n",
    "              ],\n",
    "              model=model)\n",
    "\n",
    "          answer = student.choices[0].message.content\n",
    "          q_and_a = \"\"\"role is {r}\\n question is {question}\\n\n",
    "          Answer is {answer}\"\"\".format(question=question_lst[i],answer=answer,r=role)\n",
    "          grader = openai.chat.completions.create(\n",
    "              messages = [\n",
    "\n",
    "                  {\"role\": \"system\", \"content\": text_rule_grader+history},\n",
    "                  {\"role\": \"user\",\"content\":q_and_a + warning_grader}\n",
    "              ],\n",
    "              model=model)\n",
    "          g = grader.choices[0].message.content\n",
    "          q_a_dic = {\"Role\":role,\"Question\":question_lst[i], \"Answer\":answer}\n",
    "          #print(q_a_dic)\n",
    "          try:\n",
    "            the_dic = json.loads(g)\n",
    "            warning_grade = \"\"\n",
    "          except Exception as error:\n",
    "          # handle the exception\n",
    "            print(\"An exception occurred:\", error)\n",
    "            print(\"ERROR!!!!\")\n",
    "            warning_grader = \"The grade output is only dictionary format, your last out did not match the formate. Regrade it.\"\n",
    "            error_time += 1\n",
    "            error_message = {\"Question\":question_lst[i], \"Answer\":answer, \"Error grading formate\":g}\n",
    "            update_json_file(model+\"_error.json\", error_message)\n",
    "            total+=1\n",
    "            error_score+=1\n",
    "            continue\n",
    "          #print(the_dic)\n",
    "          score = final_score(the_dic)\n",
    "          #print(g)\n",
    "          #print(score)\n",
    "          q_a_dic.update(the_dic)\n",
    "          q_a_dic[\"role\"] = role\n",
    "          q_a_dic[\"score\"] = score\n",
    "          \n",
    "          if score < threshold and bad_answer < 7:\n",
    "            #print(\"Score is lower than threshold\")\n",
    "            #print(the_dic)\n",
    "            fail_score+=1\n",
    "            total+=1\n",
    "            q_a_dic[\"pass\"] = False\n",
    "            loss = threshold - score\n",
    "            question = regenerate_student_answer(question,answer,the_dic,loss)\n",
    "            #print(question)\n",
    "            bad_answer+=1\n",
    "          else:\n",
    "            q_a_dic[\"pass\"] = True \n",
    "            if bad_answer < 7:\n",
    "                q_a_dic[\"pass\"] = True \n",
    "                pass_score+=1\n",
    "                total+=1\n",
    "            else:\n",
    "                q_a_dic[\"pass\"] = False\n",
    "                fail_score+=1\n",
    "                total+=1\n",
    "            bad_answer = 0\n",
    "            i+=1\n",
    "            if i < len(question_lst):\n",
    "              question = question_lst[i]\n",
    "            #role = random.choice(role_lst)\n",
    "          #print(q_a_dic)\n",
    "          update_json_file(model+\"_record.json\", q_a_dic)\n",
    "        else:\n",
    "          #print(f\"error too much on {question_lst[i]}\")\n",
    "          error_time = 0\n",
    "          pass_score+=1\n",
    "          total+=1\n",
    "          i+=1\n",
    "          if i < len(question_lst):\n",
    "            question = question_lst[i]\n",
    "\n",
    "    print(pass_score/total)\n",
    "    print(fail_score/total)\n",
    "    print(error_score/total)\n",
    "          #role = random.choice(role_lst)\n",
    "\n",
    "    #   final_s = final_score(the_dic)\n",
    "    #   the_dic[\"final\"] = final_s\n",
    "    #   print(final_s)\n",
    "    #   q_a_dic.update(the_dic)\n",
    "    #   update_json_file(\"record.json\", q_a_dic)\n",
    "    #   if final_s < therahold:\n",
    "    #     question = generate_student_answer(question[i],answer,the_dic,therahold-final_s)\n",
    "    #   else:\n",
    "    #     i+=1\n",
    "    #     if i < len(question_lst):\n",
    "    #       question = question_lst[i]\n",
    "    # else:\n",
    "    #   print(f\"error too much on {question_lst[i]}\")\n",
    "    #   error_time = 0\n",
    "    #   i+=1\n",
    "    #   if i < len(question_lst):\n",
    "    #       question = question_lst[i]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feature1': 'Relevance to Role', 'feature2': 'Technical Accuracy', 'feature3': 'Clarity of Explanation', 'feature4': 'Depth of Analysis', 'threshold': 25.0}\n",
      "25.0\n",
      "Check threshold and feature, is it following rule?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1. Neurosurgeon', '2. Environmental activist', '3. Fashion designer', '4. Airline pilot', '5. Zookeeper']\n",
      "Check character_list, is it following rule?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What are some common procedures performed by a neurosurgeon?', 'How can an environmental activist raise awareness about climate change?', 'What are some key factors to consider when designing a new fashion collection?', 'How do airline pilots ensure safe take-off and landing procedures?', 'What are the responsibilities of a zookeeper in maintaining animal habitats?', 'What is the role of the prefrontal cortex in decision-making?', 'How can renewable energy sources help combat environmental degradation?', 'What are some emerging trends in sustainable fashion design?', 'How do pilots navigate through turbulent weather conditions?', 'What are some common enrichment activities provided for zoo animals?', 'What are some ethical considerations in neurosurgery?', 'How do environmental activists influence policy changes at the government level?', 'What are some challenges faced by fashion designers in the industry?', 'What are the key attributes of a successful airline pilot?', 'How do zookeepers contribute to species conservation efforts?']\n",
      "Check question_list, is it following rule?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feature1': 'Relevance to Role', 'feature2': 'Technical Accuracy', 'feature3': 'Clarity of Explanation', 'feature4': 'Depth of Analysis', 'threshold': 25.0}\n",
      "{\"Relevance to Role\": Relevance to Role score , \"Technical Accuracy\": Technical Accuracy score , \"Clarity of Explanation\": Clarity of Explanation score , \"Depth of Analysis\": Depth of Analysis score , \"feedback\" : short feedback for answer }\n",
      "grade = Relevance to Role + Technical Accuracy + Clarity of Explanation + Depth of Analysis\n",
      "Check formate_grade and grade_text, are they following rule?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this task, we have these feature:['Relevance to Role', 'Technical Accuracy', 'Clarity of Explanation', 'Depth of Analysis', 25.0], and we will give the answer and question.\n",
      "    You will grade the answer base on these features strictly.\n",
      "    Each features score are in range 0 to 10, 0 means totally worst in fiels, 10 means best in fields.\n",
      "    Some questions will require answerer play as specific roles, and you will grade the answer base on the role reaction in the real world.\n",
      "    Also, you need to give short feedback for answer and it can analysis to generate a better answer. Or analysis to generate the answer which is more real for specific role.\n",
      "    The output formate is dictionary format as follow:\n",
      "    {\"Relevance to Role\": Relevance to Role score , \"Technical Accuracy\": Technical Accuracy score , \"Clarity of Explanation\": Clarity of Explanation score , \"Depth of Analysis\": Depth of Analysis score , \"feedback\" : short feedback for answer }\n",
      "    Note: Don't output others words, because any others words will be not be accpeted by json_load function.\n",
      "    Each score are int, only value for feedback can be string.\n",
      "    Here is two example:\n",
      "    Non-pass example\n",
      "    Question: You are six-year-old child, What is self-attention?\n",
      "    Answer: a mechanism used in machine learning, particularly in natural language processing (NLP) and computer vision tasks, to capture dependencies and relationships within input sequences.\n",
      "    Expected Output: {\"Relevance to Role\": 0 , \"Depth of Knowledge\": 7 , \"Clarity of Explanation\": 7 , \"Use of Professional Terminology\": 7 , \"Accuracy of Information\": 7 , \"feedback\" : “a normal 6-year-old child should not know self-attention since he/she is not master student, it is not real.” }\n",
      "    \n",
      "    pass example\n",
      "    Question: You are six-year-old child, What is self-attention?\n",
      "    Answer: Maybe it is a toy!!!\n",
      "    Expected Output: {\"Relevance to Role\": 7 , \"Depth of Knowledge\": 5 , \"Clarity of Explanation\": 7 , \"Use of Professional Terminology\": 5 , \"Accuracy of Information\": 7 ,\"feedback\" : “It is a answer from normal 6-year-old child for master students questions.” }\n",
      "    \n",
      "    Also, You can see the previous history as follow(if there is empty, it is first grade):\n",
      "\n",
      "    \n",
      "Check text_rule_grader, is it following rule?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An exception occurred: Expecting value: line 3 column 27 (char 56)\n",
      "ERROR!!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [15:30<1:02:00, 930.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4093567251461988\n",
      "0.5847953216374269\n",
      "0.005847953216374269\n",
      "An exception occurred: Expecting value: line 1 column 120 (char 119)\n",
      "ERROR!!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [28:47<42:36, 852.17s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4565916398713826\n",
      "0.5369774919614148\n",
      "0.006430868167202572\n",
      "An exception occurred: Expecting property name enclosed in double quotes: line 1 column 108 (char 107)\n",
      "ERROR!!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [43:27<28:49, 864.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45689655172413796\n",
      "0.5366379310344828\n",
      "0.00646551724137931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [1:00:34<15:28, 928.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4328125\n",
      "0.5625\n",
      "0.0046875\n",
      "An exception occurred: Expecting value: line 1 column 116 (char 115)\n",
      "ERROR!!!!\n",
      "An exception occurred: Extra data: line 1 column 603 (char 602)\n",
      "ERROR!!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [1:18:07<00:00, 937.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4197080291970803\n",
      "0.5742092457420924\n",
      "0.006082725060827251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_s = \"gpt-3.5-turbo-0125\"\n",
    "\n",
    "while True:\n",
    "    threshold, feature_dict = rule_gen(model_s,policy_create)\n",
    "    print(\"Check threshold and feature, is it following rule?\")\n",
    "    user_check = input()\n",
    "    if user_check == \"Yes\":\n",
    "        break\n",
    "\n",
    "while True:\n",
    "    character_list = characterGen(model_s)\n",
    "    print(\"Check character_list, is it following rule?\")\n",
    "    user_check = input()\n",
    "    if user_check == \"Yes\":\n",
    "        break\n",
    "        \n",
    "while True:\n",
    "    question_list = questions_gen(model_s)\n",
    "    print(\"Check question_list, is it following rule?\")\n",
    "    user_check = input()\n",
    "    if user_check == \"Yes\":\n",
    "        break\n",
    "\n",
    "while True:\n",
    "    formate_grade, grade_text = feature_gen(model_s)\n",
    "    print(\"Check formate_grade and grade_text, are they following rule?\")\n",
    "    user_check = input()\n",
    "    if user_check == \"Yes\":\n",
    "        break\n",
    "\n",
    "while True:\n",
    "    text_rule_grader = text_ruleMake(feature_dict,formate_grade)\n",
    "    print(\"Check text_rule_grader, is it following rule?\")\n",
    "    user_check = input()\n",
    "    if user_check == \"Yes\":\n",
    "        break\n",
    "generate_student_answer(question_list,text_rule_grader,threshold,5,model_s,character_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_s = \"gpt-4-turbo\"\n",
    "\n",
    "while True:\n",
    "    threshold, feature_dict = rule_gen(model_s,policy_create)\n",
    "    print(\"Check threshold and feature, is it following rule?\")\n",
    "    user_check = input()\n",
    "    if user_check == \"Yes\":\n",
    "        break\n",
    "\n",
    "while True:\n",
    "    character_list = characterGen(model_s)\n",
    "    print(\"Check character_list, is it following rule?\")\n",
    "    user_check = input()\n",
    "    if user_check == \"Yes\":\n",
    "        break\n",
    "        \n",
    "while True:\n",
    "    question_list = questions_gen(model_s)\n",
    "    print(\"Check question_list, is it following rule?\")\n",
    "    user_check = input()\n",
    "    if user_check == \"Yes\":\n",
    "        break\n",
    "\n",
    "while True:\n",
    "    formate_grade, grade_text = feature_gen(model_s)\n",
    "    print(\"Check formate_grade and grade_text, are they following rule?\")\n",
    "    user_check = input()\n",
    "    if user_check == \"Yes\":\n",
    "        break\n",
    "\n",
    "while True:\n",
    "    text_rule_grader = text_ruleMake(feature_dict,formate_grade)\n",
    "    print(\"Check text_rule_grader, is it following rule?\")\n",
    "    user_check = input()\n",
    "    if user_check == \"Yes\":\n",
    "        break\n",
    "generate_student_answer(question_list,text_rule_grader,threshold,2,model_s,character_list)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "566",
   "language": "python",
   "name": "566"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
